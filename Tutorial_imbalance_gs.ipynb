{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c4d5a1d-f708-4b69-93b0-e727fe2fe8e5",
   "metadata": {},
   "source": [
    "# More accurate ML example\n",
    "\n",
    "Here we are working with data from [Kaggle](https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset?resource=download)... our goal is to basically predict if a person has diabettes or not.\n",
    "\n",
    "I wont try to create a perfect model, i will just show how we can use easydags for ML tasks. Lets suppose that we have a classification task where there is a huge imbalance... usually our first question is:\n",
    "\n",
    "1. Do nothing with the data?\n",
    "2. Undersample?\n",
    "3. Oversample?\n",
    "4. Smote?\n",
    "\n",
    "The first part of this notebook does such task in a \"usual\" way but we know that we can train each option in paralallel so that at the end we can do it in a faster way.\n",
    "\n",
    "\n",
    "## Prepare the functions that we need\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6120ae56-492c-4f13-b9fa-f455adffa921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def base_rf(X_train,y_train, name = 'base'):\n",
    "    #Basically we need a function to create a rf object trained with the data\n",
    "\n",
    "    rf = RandomForestClassifier()\n",
    "    \n",
    "    params = {\n",
    "        'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "        'n_estimators': [10, 30, 100]\n",
    "    }\n",
    "    \n",
    "    clf = GridSearchCV(rf, param_grid=params, scoring='recall')\n",
    "    clf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    clf.name = name\n",
    "\n",
    "    return clf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e8beff-9403-42e7-9248-d432e5b0bb9f",
   "metadata": {},
   "source": [
    "\n",
    "# Usual way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da741b5e-465a-4365-b224-6e23aaed1a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3      4\n",
      "0  0.799641  0.698039  0.935857  0.970267   base\n",
      "0  0.766347  0.721569  0.817052    0.9626  smote\n",
      "0  0.783864  0.723922   0.85463  0.966067   over\n",
      "0  0.596203  0.911373  0.443004  0.895067  under\n",
      "time: 283 seconds\n",
      "CPU times: user 4min 41s, sys: 1.33 s, total: 4min 42s\n",
      "Wall time: 4min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "t = time.time()\n",
    "\n",
    "\n",
    "data = pd.read_csv('data/diabetes_prediction_dataset.csv')\n",
    "df = pd.get_dummies(data)\n",
    "features = df[[c for c in df.columns if c not in ['diabetes','gender_Other', 'smoking_history_No Info']]]\n",
    "target = df[['diabetes']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.15, random_state=40, stratify=target)\n",
    "\n",
    "# base\n",
    "base = base_rf(X_train,y_train)\n",
    "\n",
    "# under\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "X_rus, y_rus = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "under = base_rf(X_rus,y_rus, 'under')\n",
    "\n",
    "\n",
    "#over\n",
    "ros = RandomOverSampler(sampling_strategy=0.5)\n",
    "\n",
    "X_ros, y_ros = ros.fit_resample(X_train, y_train )\n",
    "\n",
    "\n",
    "over = base_rf(X_ros,y_ros,'over')\n",
    "\n",
    "\n",
    "#Smote\n",
    "\n",
    "smote = SMOTE()\n",
    "\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "smote = base_rf(X_smote,y_smote, 'smote')\n",
    "\n",
    "\n",
    "# metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "metrics_list = []\n",
    "for model in [base,smote, over,under]:\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    aux = pd.DataFrame([metrics.f1_score(y_test, y_pred),\n",
    "    metrics.recall_score(y_test, y_pred),\n",
    "    metrics.precision_score(y_test, y_pred),\n",
    "    metrics.accuracy_score(y_test, y_pred),\n",
    "    model.name])\n",
    "    metrics_list.append(aux.transpose())\n",
    "\n",
    "metrics = pd.concat(metrics_list)\n",
    "print(metrics)\n",
    "\n",
    "\n",
    "\n",
    "print(f'time: {int(time.time() - t)} seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26ea6a5-3438-48e6-99a8-c66da60dea99",
   "metadata": {},
   "source": [
    "# As a dag\n",
    "\n",
    "\n",
    "We will need this nodes\n",
    "\n",
    "- Pre pro\n",
    "- base\n",
    "- under\n",
    "- over\n",
    "- smote\n",
    "- final metrics\n",
    "\n",
    "The steps to build and run are the following:\n",
    "\n",
    "1. The common task before defining a dag is defining the function that we will run in each node\n",
    "2. Creates nodes (please check that we did not add the dependency directly in here in this example)\n",
    "3. Define dependencies using >> (thats the Hard dependency operator)\n",
    "4. Create the nodes list using all the ExecNodes availables in the envioronment... if you do not want to do it with all the created nodes please create the list by yourself as usual\n",
    "5. Create the dag with the list of nodes\n",
    "6. Run the dag\n",
    "7. Check the html output with one iframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35dd4134-d4fc-4a92-b4f9-942c04fbc4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-15 11:16:20.815 | INFO     | easydags.node:execute:146 - Start executing pre_pro at 2023-06-15, 11:16:20\n",
      "2023-06-15 11:16:21.073 | INFO     | easydags.node:execute:146 - Start executing smote at 2023-06-15, 11:16:21\n",
      "2023-06-15 11:16:21.073 | INFO     | easydags.node:execute:146 - Start executing over at 2023-06-15, 11:16:21\n",
      "2023-06-15 11:16:21.073 | INFO     | easydags.node:execute:146 - Start executing base at 2023-06-15, 11:16:21\n",
      "2023-06-15 11:17:37.426 | INFO     | easydags.node:execute:146 - Start executing under at 2023-06-15, 11:17:37\n",
      "2023-06-15 11:19:02.651 | INFO     | easydags.node:execute:146 - Start executing metrics at 2023-06-15, 11:19:02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drawing\n",
      "time: 162 seconds\n",
      "CPU times: user 6min 2s, sys: 1.05 s, total: 6min 3s\n",
      "Wall time: 2min 42s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"Real ML imbalance and grid search_states_run.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fcc405979d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from easydags import  ExecNode, DAG, search_nodes\n",
    "from IPython.display import IFrame\n",
    "\n",
    "import time\n",
    "t = time.time()\n",
    "\n",
    "\n",
    "# defining the functions\n",
    "def pre_pro():\n",
    "    df = pd.get_dummies(data)\n",
    "    features = df[[c for c in df.columns if c not in ['diabetes','gender_Other', 'smoking_history_No Info']]]\n",
    "    target = df[['diabetes']]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.15, random_state=40, stratify=target)\n",
    "\n",
    "    return (X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n",
    "\n",
    "def model_base (**kwargs):\n",
    "    X = kwargs['data'][0]\n",
    "    y = kwargs['data'][2]\n",
    "    base = base_rf(X,y)\n",
    "    return base\n",
    "\n",
    "def model_under (**kwargs):\n",
    "    X = kwargs['data'][0]\n",
    "    y = kwargs['data'][2]\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "    X_rus, y_rus = rus.fit_resample(X, y)\n",
    "    \n",
    "    under = base_rf(X_rus,y_rus, 'under')\n",
    "    \n",
    "    return under\n",
    "\n",
    "def model_over (**kwargs):\n",
    "    X = kwargs['data'][0]\n",
    "    y = kwargs['data'][2]\n",
    "    ros = RandomOverSampler(sampling_strategy=0.5)\n",
    "\n",
    "    X_ros, y_ros = ros.fit_resample(X, y )\n",
    "    \n",
    "    over = base_rf(X_ros,y_ros,'over')\n",
    "    \n",
    "    return over\n",
    "\n",
    "def model_smote (**kwargs):\n",
    "    X = kwargs['data'][0]\n",
    "    y = kwargs['data'][2]\n",
    "    smote = SMOTE()\n",
    "\n",
    "    X_smote, y_smote = smote.fit_resample(X, y)\n",
    "     \n",
    "    smote = base_rf(X_smote,y_smote, 'smote')\n",
    "    \n",
    "    return over\n",
    "\n",
    "def models_metrics (**kwargs):\n",
    "    X_test = kwargs['data'][1]\n",
    "    y_test = kwargs['data'][3]\n",
    "\n",
    "    base = kwargs['base']\n",
    "    smote = kwargs['smote']\n",
    "    under = kwargs['under']\n",
    "    over = kwargs['over']\n",
    "    \n",
    "\n",
    "    from sklearn import metrics\n",
    "    metrics_list = []\n",
    "    for model in [base,smote, over,under]:\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        aux = pd.DataFrame([metrics.f1_score(y_test, y_pred),\n",
    "        metrics.recall_score(y_test, y_pred),\n",
    "        metrics.precision_score(y_test, y_pred),\n",
    "        metrics.accuracy_score(y_test, y_pred),\n",
    "        model.name])\n",
    "        metrics_list.append(aux.transpose())\n",
    "    \n",
    "    metrics = pd.concat(metrics_list)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# defining the nodes\n",
    "node_prepro = ExecNode('pre_pro', output_name = 'data',exec_function = pre_pro)\n",
    "\n",
    "node_metrics = ExecNode('metrics',exec_function = models_metrics)\n",
    "\n",
    "node_base = ExecNode('base', output_name = 'base',exec_function = model_base)\n",
    "\n",
    "node_under = ExecNode('under', output_name = 'under',exec_function = model_under)\n",
    "\n",
    "node_over = ExecNode('over', output_name = 'over',exec_function = model_over)\n",
    "\n",
    "node_smote = ExecNode('smote', output_name = 'smote',exec_function = model_smote)\n",
    "\n",
    "\n",
    "# Define dependencies\n",
    "node_prepro >> node_base >> node_metrics\n",
    "\n",
    "node_prepro >> node_under >> node_metrics\n",
    "\n",
    "node_prepro >> node_over >> node_metrics\n",
    "\n",
    "node_prepro >> node_smote >> node_metrics\n",
    "\n",
    "node_prepro  >> node_metrics\n",
    "\n",
    "# Creating the list of nodes... you can also do it by yourself! \n",
    "#nodes = [node_prepro, node_base,node_under,node_over,node_smote,node_metrics] \n",
    "nodes = [] \n",
    "globs = globals().copy()\n",
    "for obj_name in globs:         \n",
    "    if isinstance(globs[obj_name], ExecNode):\n",
    "        nodes.append(globs[obj_name])\n",
    "\n",
    "\n",
    "dag = DAG(nodes,name = 'Real ML imbalance and grid search',max_concurrency=3, debug = False, error_type_fatal= False)\n",
    "\n",
    "dag.execute()\n",
    "    \n",
    "\n",
    "print(f'time: {int(time.time() - t)} seconds')\n",
    "\n",
    "\n",
    "IFrame(src=f\"{dag.name}_states_run.html\", width='100%', height=600)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65c3f96-3f1f-4897-963d-35d40bc5ea46",
   "metadata": {},
   "source": [
    "## You can spect the time in each node to understand why this is 2x faster and not 4x... but hey! 2x is still a good performance enhance!\n",
    "\n",
    "The reason is basically that not all the inner nodes have the same comp time\n",
    "\n",
    "\n",
    "# Final DAG\n",
    "\n",
    "If you run this tutorial you will get the dag html by yourself, here i will add a png version so you can check it out without running the tutorial:\n",
    "\n",
    "[Motivation](https://raw.githubusercontent.com/magralo/easydags/main/resource_readme/dag_tut_ml_imb.png)\n",
    "              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e79202-f9d8-467d-b061-6f555e811cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
