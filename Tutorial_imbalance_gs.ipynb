{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c4d5a1d-f708-4b69-93b0-e727fe2fe8e5",
   "metadata": {},
   "source": [
    "# More accurate ML example\n",
    "\n",
    "Here we are working with data from [Kaggle](https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset?resource=download)... our goal is to basically predict if a person has diabettes or not.\n",
    "\n",
    "I wont try to create a perfect model, i will just show how we can use easydags for ML tasks. Lets suppose that we have a classification task where there is a huge imbalance... usually our first question is:\n",
    "\n",
    "1. Do nothing with the data?\n",
    "2. Undersample?\n",
    "3. Oversample?\n",
    "4. Smote?\n",
    "\n",
    "The first part of this notebook does such task in a \"usual\" way but we know that we can train each option in paralallel so that at the end we can do it in a faster way.\n",
    "\n",
    "\n",
    "## Prepare the functions that we need\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6120ae56-492c-4f13-b9fa-f455adffa921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def base_rf(X_train,y_train, name = 'base'):\n",
    "    #Basically we need a function to create a rf object trained with the data\n",
    "\n",
    "    rf = RandomForestClassifier()\n",
    "    \n",
    "    params = {\n",
    "        'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "        'n_estimators': [10, 30, 100]\n",
    "    }\n",
    "    \n",
    "    clf = GridSearchCV(rf, param_grid=params, scoring='recall')\n",
    "    clf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    clf.name = name\n",
    "\n",
    "    return clf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e8beff-9403-42e7-9248-d432e5b0bb9f",
   "metadata": {},
   "source": [
    "\n",
    "# Usual way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da741b5e-465a-4365-b224-6e23aaed1a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3      4\n",
      "0  0.796959  0.698824  0.927159  0.969733   base\n",
      "0  0.777639   0.73098   0.83066  0.964467  smote\n",
      "0  0.781395  0.724706  0.847706  0.965533   over\n",
      "0  0.595165  0.907451  0.442786  0.895067  under\n",
      "time: 279 seconds\n",
      "CPU times: user 4min 38s, sys: 688 ms, total: 4min 39s\n",
      "Wall time: 4min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "t = time.time()\n",
    "\n",
    "\n",
    "data = pd.read_csv('data/diabetes_prediction_dataset.csv')\n",
    "df = pd.get_dummies(data)\n",
    "features = df[[c for c in df.columns if c not in ['diabetes','gender_Other', 'smoking_history_No Info']]]\n",
    "target = df[['diabetes']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.15, random_state=40, stratify=target)\n",
    "\n",
    "# base\n",
    "base = base_rf(X_train,y_train)\n",
    "\n",
    "# under\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "X_rus, y_rus = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "under = base_rf(X_rus,y_rus, 'under')\n",
    "\n",
    "\n",
    "#over\n",
    "ros = RandomOverSampler(sampling_strategy=0.5)\n",
    "\n",
    "X_ros, y_ros = ros.fit_resample(X_train, y_train )\n",
    "\n",
    "\n",
    "over = base_rf(X_ros,y_ros,'over')\n",
    "\n",
    "\n",
    "#Smote\n",
    "\n",
    "smote = SMOTE()\n",
    "\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "smote = base_rf(X_smote,y_smote, 'smote')\n",
    "\n",
    "\n",
    "# metrics\n",
    "\n",
    "from sklearn import metrics\n",
    "metrics_list = []\n",
    "for model in [base,smote, over,under]:\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    aux = pd.DataFrame([metrics.f1_score(y_test, y_pred),\n",
    "    metrics.recall_score(y_test, y_pred),\n",
    "    metrics.precision_score(y_test, y_pred),\n",
    "    metrics.accuracy_score(y_test, y_pred),\n",
    "    model.name])\n",
    "    metrics_list.append(aux.transpose())\n",
    "\n",
    "metrics = pd.concat(metrics_list)\n",
    "print(metrics)\n",
    "\n",
    "\n",
    "\n",
    "print(f'time: {int(time.time() - t)} seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26ea6a5-3438-48e6-99a8-c66da60dea99",
   "metadata": {},
   "source": [
    "# As a dag\n",
    "\n",
    "\n",
    "We will need this nodes\n",
    "\n",
    "- Pre pro\n",
    "- base\n",
    "- under\n",
    "- over\n",
    "- smote\n",
    "- final metrics\n",
    "\n",
    "The steps to build and run are the following:\n",
    "\n",
    "1. The common task before defining a dag is defining the function that we will run in each node\n",
    "2. Creates nodes (please check that we did not add the dependency directly in here in this example)\n",
    "3. Define dependencies using >> (thats the Hard dependency operator)\n",
    "4. Create the nodes list using all the ExecNodes availables in the envioronment... if you do not want to do it with all the created nodes please create the list by yourself as usual\n",
    "5. Create the dag with the list of nodes\n",
    "6. Run the dag\n",
    "7. Check the html output with one iframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35dd4134-d4fc-4a92-b4f9-942c04fbc4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 14:43:37.381 | INFO     | easydags.node:execute:146 - Start executing pre_pro at 2023-06-13, 14:43:37\n",
      "2023-06-13 14:43:37.632 | INFO     | easydags.node:execute:146 - Start executing base at 2023-06-13, 14:43:37\n",
      "2023-06-13 14:43:37.632 | INFO     | easydags.node:execute:146 - Start executing smote at 2023-06-13, 14:43:37\n",
      "2023-06-13 14:43:37.633 | INFO     | easydags.node:execute:146 - Start executing under at 2023-06-13, 14:43:37\n",
      "2023-06-13 14:43:50.982 | INFO     | easydags.node:execute:146 - Start executing over at 2023-06-13, 14:43:50\n",
      "2023-06-13 14:45:55.020 | INFO     | easydags.node:execute:146 - Start executing metrics at 2023-06-13, 14:45:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drawing\n",
      "time: 138 seconds\n",
      "CPU times: user 5min 1s, sys: 977 ms, total: 5min 2s\n",
      "Wall time: 2min 18s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"Real ML imbalance and grid search_states_run.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fc3f038d0f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from easydags import  ExecNode, DAG, search_nodes\n",
    "from IPython.display import IFrame\n",
    "\n",
    "import time\n",
    "t = time.time()\n",
    "\n",
    "\n",
    "# defining the functions\n",
    "def pre_pro():\n",
    "    df = pd.get_dummies(data)\n",
    "    features = df[[c for c in df.columns if c not in ['diabetes','gender_Other', 'smoking_history_No Info']]]\n",
    "    target = df[['diabetes']]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.15, random_state=40, stratify=target)\n",
    "\n",
    "    return (X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n",
    "\n",
    "def model_base (**kwargs):\n",
    "    X = kwargs['data'][0]\n",
    "    y = kwargs['data'][2]\n",
    "    base = base_rf(X,y)\n",
    "    return base\n",
    "\n",
    "def model_under (**kwargs):\n",
    "    X = kwargs['data'][0]\n",
    "    y = kwargs['data'][2]\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "    X_rus, y_rus = rus.fit_resample(X, y)\n",
    "    \n",
    "    under = base_rf(X_rus,y_rus, 'under')\n",
    "    \n",
    "    return under\n",
    "\n",
    "def model_over (**kwargs):\n",
    "    X = kwargs['data'][0]\n",
    "    y = kwargs['data'][2]\n",
    "    ros = RandomOverSampler(sampling_strategy=0.5)\n",
    "\n",
    "    X_ros, y_ros = ros.fit_resample(X, y )\n",
    "    \n",
    "    over = base_rf(X_ros,y_ros,'over')\n",
    "    \n",
    "    return over\n",
    "\n",
    "def model_smote (**kwargs):\n",
    "    X = kwargs['data'][0]\n",
    "    y = kwargs['data'][2]\n",
    "    smote = SMOTE()\n",
    "\n",
    "    X_smote, y_smote = smote.fit_resample(X, y)\n",
    "     \n",
    "    smote = base_rf(X_smote,y_smote, 'smote')\n",
    "    \n",
    "    return over\n",
    "\n",
    "def models_metrics (**kwargs):\n",
    "    X_test = kwargs['data'][1]\n",
    "    y_test = kwargs['data'][3]\n",
    "\n",
    "    base = kwargs['base']\n",
    "    smote = kwargs['smote']\n",
    "    under = kwargs['under']\n",
    "    over = kwargs['over']\n",
    "    \n",
    "\n",
    "    from sklearn import metrics\n",
    "    metrics_list = []\n",
    "    for model in [base,smote, over,under]:\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        aux = pd.DataFrame([metrics.f1_score(y_test, y_pred),\n",
    "        metrics.recall_score(y_test, y_pred),\n",
    "        metrics.precision_score(y_test, y_pred),\n",
    "        metrics.accuracy_score(y_test, y_pred),\n",
    "        model.name])\n",
    "        metrics_list.append(aux.transpose())\n",
    "    \n",
    "    metrics = pd.concat(metrics_list)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# defining the nodes\n",
    "node_prepro = ExecNode('pre_pro', output_name = 'data',exec_function = pre_pro)\n",
    "\n",
    "node_metrics = ExecNode('metrics',exec_function = models_metrics)\n",
    "\n",
    "node_base = ExecNode('base', output_name = 'base',exec_function = model_base)\n",
    "\n",
    "node_under = ExecNode('under', output_name = 'under',exec_function = model_under)\n",
    "\n",
    "node_over = ExecNode('over', output_name = 'over',exec_function = model_over)\n",
    "\n",
    "node_smote = ExecNode('smote', output_name = 'smote',exec_function = model_smote)\n",
    "\n",
    "\n",
    "# Define dependencies\n",
    "node_prepro >> node_base >> node_metrics\n",
    "\n",
    "node_prepro >> node_under >> node_metrics\n",
    "\n",
    "node_prepro >> node_over >> node_metrics\n",
    "\n",
    "node_prepro >> node_smote >> node_metrics\n",
    "\n",
    "node_prepro  >> node_metrics\n",
    "\n",
    "# Creating the list of nodes... you can also do it by yourself! \n",
    "#nodes = [node_prepro, node_base,node_under,node_over,node_smote,node_metrics] \n",
    "nodes = [] \n",
    "globs = globals().copy()\n",
    "for obj_name in globs:         \n",
    "    if isinstance(globs[obj_name], ExecNode):\n",
    "        nodes.append(globs[obj_name])\n",
    "\n",
    "\n",
    "dag = DAG(nodes,name = 'Real ML imbalance and grid search',max_concurrency=3, debug = False, error_type_fatal= False)\n",
    "\n",
    "dag.execute()\n",
    "    \n",
    "\n",
    "print(f'time: {int(time.time() - t)} seconds')\n",
    "\n",
    "\n",
    "IFrame(src=f\"{dag.name}_states_run.html\", width='100%', height=600)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65c3f96-3f1f-4897-963d-35d40bc5ea46",
   "metadata": {},
   "source": [
    "## You can spect the time in each node to understand why this is 2x faster and not 4x... but hey! 2x is still a good performance enhance!\n",
    "\n",
    "The reason is basically that not all the inner nodes have the same comp time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
